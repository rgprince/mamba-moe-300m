# Colab Quick Test

[![Open In Colab](https://colab.research.google.com/assets/colab-badge.svg)](https://colab.research.google.com/github/rgprince/mamba-moe-300m/blob/main/notebooks/colab_quick_test.md)

## âš¡ Quick Setup and Test on Colab TPU

### Important: Make sure you're using a fresh Colab session!

### Step 1: Setup Runtime
```
Runtime â†’ Change runtime type â†’ TPU
```

### Step 2: Clone and Install (Copy-paste this entire block)
```python
# Clean start - remove any old clones
!rm -rf mamba-moe-300m

# Clone fresh
!git clone https://github.com/rgprince/mamba-moe-300m.git
%cd mamba-moe-300m

# Install dependencies
!pip install -q jax[tpu] flax optax chex einops pyyaml pydantic

print("âœ… Setup complete!")
```

### Step 3: Run Simple Test
```python
!python3 scripts/test_model_simple.py
```

### Expected Output:
```
============================================================
Mamba-MoE 300M - Simple Test
============================================================

[1/5] Testing JAX...
âœ“ JAX 0.4.x imported successfully

[2/5] Testing Flax...
âœ“ Flax imported successfully

[3/5] Testing model imports...
âœ“ Model package imported successfully

[4/5] Loading model config...
âœ“ Config loaded: mamba-moe-300m-v1
  - Layers: 24
  - Hidden dim: 1024
  - Estimated params: XXX.XM

[5/5] Testing model forward pass...
âœ“ Model created
âœ“ Input created: (2, 64)
  Initializing parameters...
âœ“ Model initialized: XXX.XM parameters
  Running forward pass...
âœ“ Forward pass complete
  Output shape: (2, 64, 32000)
  Expected: (2, 64, 32000)
âœ“ Output shape correct!

============================================================
âœ… ALL TESTS PASSED!
============================================================
```

---

## ğŸ› Troubleshooting

### Error: "No module named 'src'"
**Solution**: Make sure you ran `%cd mamba-moe-300m` after cloning

### Error: "ImportError: cannot import name 'training'"
**Solution**: You have an old version. Run:
```python
!rm -rf mamba-moe-300m
!git clone https://github.com/rgprince/mamba-moe-300m.git
```

### Error: "No module named 'jax'"
**Solution**: Install dependencies:
```python
!pip install jax[tpu] flax optax
```

---

## ğŸ“Š What This Tests

- âœ… JAX/Flax imports work
- âœ… Model package loads without circular imports
- âœ… Config parsing works
- âœ… Model instantiation succeeds
- âœ… Forward pass completes
- âœ… Output shape is correct
- âœ… All ~300M parameters initialized

---

## ğŸš€ Next Steps

If all tests pass:
1. **Architecture is validated!** âœ…
2. Next: Implement training loop (Phase 2)
3. Then: Prepare data pipeline
4. Finally: Train the model!

**Repo**: https://github.com/rgprince/mamba-moe-300m
